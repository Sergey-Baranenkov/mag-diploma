{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T15:10:53.071624841Z",
     "start_time": "2024-02-24T15:10:53.025922499Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Получаем абсолютный путь к корневой директории проекта (директория выше текущей)\n",
    "root_path = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "# Добавляем корневую директорию в sys.path\n",
    "if root_path not in sys.path:\n",
    "    sys.path.append(root_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T15:10:53.072087279Z",
     "start_time": "2024-02-24T15:10:53.070921561Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import torch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T15:10:53.870523842Z",
     "start_time": "2024-02-24T15:10:53.071991315Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# checkpoint = torch.load('../checkpoint/audiosep_base_4M_steps.ckpt')\n",
    "checkpoint = torch.load('../checkpoints/train_audiosep_lora/audiosep_lora_musdb18,devices=1/step=1482.ckpt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T15:11:24.045337133Z",
     "start_time": "2024-02-24T15:11:23.996927398Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'loops', 'callbacks', 'optimizer_states', 'lr_schedulers'])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T15:11:24.648885765Z",
     "start_time": "2024-02-24T15:11:24.637739501Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "odict_keys(['model.base_model.model.ss_model.base.stft.conv_real.weight', 'model.base_model.model.ss_model.base.stft.conv_imag.weight', 'model.base_model.model.ss_model.base.istft.ola_window', 'model.base_model.model.ss_model.base.istft.conv_real.weight', 'model.base_model.model.ss_model.base.istft.conv_imag.weight', 'model.base_model.model.ss_model.base.bn0.weight', 'model.base_model.model.ss_model.base.bn0.bias', 'model.base_model.model.ss_model.base.bn0.running_mean', 'model.base_model.model.ss_model.base.bn0.running_var', 'model.base_model.model.ss_model.base.bn0.num_batches_tracked', 'model.base_model.model.ss_model.base.pre_conv.base_layer.weight', 'model.base_model.model.ss_model.base.pre_conv.base_layer.bias', 'model.base_model.model.ss_model.base.pre_conv.lora_A.default.weight', 'model.base_model.model.ss_model.base.pre_conv.lora_B.default.weight', 'model.base_model.model.ss_model.base.encoder_block1.conv_block1.bn1.weight', 'model.base_model.model.ss_model.base.encoder_block1.conv_block1.bn1.bias', 'model.base_model.model.ss_model.base.encoder_block1.conv_block1.bn1.running_mean', 'model.base_model.model.ss_model.base.encoder_block1.conv_block1.bn1.running_var', 'model.base_model.model.ss_model.base.encoder_block1.conv_block1.bn1.num_batches_tracked', 'model.base_model.model.ss_model.base.encoder_block1.conv_block1.bn2.weight', 'model.base_model.model.ss_model.base.encoder_block1.conv_block1.bn2.bias', 'model.base_model.model.ss_model.base.encoder_block1.conv_block1.bn2.running_mean', 'model.base_model.model.ss_model.base.encoder_block1.conv_block1.bn2.running_var', 'model.base_model.model.ss_model.base.encoder_block1.conv_block1.bn2.num_batches_tracked', 'model.base_model.model.ss_model.base.encoder_block1.conv_block1.conv1.base_layer.weight', 'model.base_model.model.ss_model.base.encoder_block1.conv_block1.conv1.lora_A.default.weight', 'model.base_model.model.ss_model.base.encoder_block1.conv_block1.conv1.lora_B.default.weight', 'model.base_model.model.ss_model.base.encoder_block1.conv_block1.conv2.base_layer.weight', 'model.base_model.model.ss_model.base.encoder_block1.conv_block1.conv2.lora_A.default.weight', 'model.base_model.model.ss_model.base.encoder_block1.conv_block1.conv2.lora_B.default.weight', 'model.base_model.model.ss_model.base.encoder_block2.conv_block1.bn1.weight', 'model.base_model.model.ss_model.base.encoder_block2.conv_block1.bn1.bias', 'model.base_model.model.ss_model.base.encoder_block2.conv_block1.bn1.running_mean', 'model.base_model.model.ss_model.base.encoder_block2.conv_block1.bn1.running_var', 'model.base_model.model.ss_model.base.encoder_block2.conv_block1.bn1.num_batches_tracked', 'model.base_model.model.ss_model.base.encoder_block2.conv_block1.bn2.weight', 'model.base_model.model.ss_model.base.encoder_block2.conv_block1.bn2.bias', 'model.base_model.model.ss_model.base.encoder_block2.conv_block1.bn2.running_mean', 'model.base_model.model.ss_model.base.encoder_block2.conv_block1.bn2.running_var', 'model.base_model.model.ss_model.base.encoder_block2.conv_block1.bn2.num_batches_tracked', 'model.base_model.model.ss_model.base.encoder_block2.conv_block1.conv1.base_layer.weight', 'model.base_model.model.ss_model.base.encoder_block2.conv_block1.conv1.lora_A.default.weight', 'model.base_model.model.ss_model.base.encoder_block2.conv_block1.conv1.lora_B.default.weight', 'model.base_model.model.ss_model.base.encoder_block2.conv_block1.conv2.base_layer.weight', 'model.base_model.model.ss_model.base.encoder_block2.conv_block1.conv2.lora_A.default.weight', 'model.base_model.model.ss_model.base.encoder_block2.conv_block1.conv2.lora_B.default.weight', 'model.base_model.model.ss_model.base.encoder_block2.conv_block1.shortcut.base_layer.weight', 'model.base_model.model.ss_model.base.encoder_block2.conv_block1.shortcut.base_layer.bias', 'model.base_model.model.ss_model.base.encoder_block2.conv_block1.shortcut.lora_A.default.weight', 'model.base_model.model.ss_model.base.encoder_block2.conv_block1.shortcut.lora_B.default.weight', 'model.base_model.model.ss_model.base.encoder_block3.conv_block1.bn1.weight', 'model.base_model.model.ss_model.base.encoder_block3.conv_block1.bn1.bias', 'model.base_model.model.ss_model.base.encoder_block3.conv_block1.bn1.running_mean', 'model.base_model.model.ss_model.base.encoder_block3.conv_block1.bn1.running_var', 'model.base_model.model.ss_model.base.encoder_block3.conv_block1.bn1.num_batches_tracked', 'model.base_model.model.ss_model.base.encoder_block3.conv_block1.bn2.weight', 'model.base_model.model.ss_model.base.encoder_block3.conv_block1.bn2.bias', 'model.base_model.model.ss_model.base.encoder_block3.conv_block1.bn2.running_mean', 'model.base_model.model.ss_model.base.encoder_block3.conv_block1.bn2.running_var', 'model.base_model.model.ss_model.base.encoder_block3.conv_block1.bn2.num_batches_tracked', 'model.base_model.model.ss_model.base.encoder_block3.conv_block1.conv1.base_layer.weight', 'model.base_model.model.ss_model.base.encoder_block3.conv_block1.conv1.lora_A.default.weight', 'model.base_model.model.ss_model.base.encoder_block3.conv_block1.conv1.lora_B.default.weight', 'model.base_model.model.ss_model.base.encoder_block3.conv_block1.conv2.base_layer.weight', 'model.base_model.model.ss_model.base.encoder_block3.conv_block1.conv2.lora_A.default.weight', 'model.base_model.model.ss_model.base.encoder_block3.conv_block1.conv2.lora_B.default.weight', 'model.base_model.model.ss_model.base.encoder_block3.conv_block1.shortcut.base_layer.weight', 'model.base_model.model.ss_model.base.encoder_block3.conv_block1.shortcut.base_layer.bias', 'model.base_model.model.ss_model.base.encoder_block3.conv_block1.shortcut.lora_A.default.weight', 'model.base_model.model.ss_model.base.encoder_block3.conv_block1.shortcut.lora_B.default.weight', 'model.base_model.model.ss_model.base.encoder_block4.conv_block1.bn1.weight', 'model.base_model.model.ss_model.base.encoder_block4.conv_block1.bn1.bias', 'model.base_model.model.ss_model.base.encoder_block4.conv_block1.bn1.running_mean', 'model.base_model.model.ss_model.base.encoder_block4.conv_block1.bn1.running_var', 'model.base_model.model.ss_model.base.encoder_block4.conv_block1.bn1.num_batches_tracked', 'model.base_model.model.ss_model.base.encoder_block4.conv_block1.bn2.weight', 'model.base_model.model.ss_model.base.encoder_block4.conv_block1.bn2.bias', 'model.base_model.model.ss_model.base.encoder_block4.conv_block1.bn2.running_mean', 'model.base_model.model.ss_model.base.encoder_block4.conv_block1.bn2.running_var', 'model.base_model.model.ss_model.base.encoder_block4.conv_block1.bn2.num_batches_tracked', 'model.base_model.model.ss_model.base.encoder_block4.conv_block1.conv1.base_layer.weight', 'model.base_model.model.ss_model.base.encoder_block4.conv_block1.conv1.lora_A.default.weight', 'model.base_model.model.ss_model.base.encoder_block4.conv_block1.conv1.lora_B.default.weight', 'model.base_model.model.ss_model.base.encoder_block4.conv_block1.conv2.base_layer.weight', 'model.base_model.model.ss_model.base.encoder_block4.conv_block1.conv2.lora_A.default.weight', 'model.base_model.model.ss_model.base.encoder_block4.conv_block1.conv2.lora_B.default.weight', 'model.base_model.model.ss_model.base.encoder_block4.conv_block1.shortcut.base_layer.weight', 'model.base_model.model.ss_model.base.encoder_block4.conv_block1.shortcut.base_layer.bias', 'model.base_model.model.ss_model.base.encoder_block4.conv_block1.shortcut.lora_A.default.weight', 'model.base_model.model.ss_model.base.encoder_block4.conv_block1.shortcut.lora_B.default.weight', 'model.base_model.model.ss_model.base.encoder_block5.conv_block1.bn1.weight', 'model.base_model.model.ss_model.base.encoder_block5.conv_block1.bn1.bias', 'model.base_model.model.ss_model.base.encoder_block5.conv_block1.bn1.running_mean', 'model.base_model.model.ss_model.base.encoder_block5.conv_block1.bn1.running_var', 'model.base_model.model.ss_model.base.encoder_block5.conv_block1.bn1.num_batches_tracked', 'model.base_model.model.ss_model.base.encoder_block5.conv_block1.bn2.weight', 'model.base_model.model.ss_model.base.encoder_block5.conv_block1.bn2.bias', 'model.base_model.model.ss_model.base.encoder_block5.conv_block1.bn2.running_mean', 'model.base_model.model.ss_model.base.encoder_block5.conv_block1.bn2.running_var', 'model.base_model.model.ss_model.base.encoder_block5.conv_block1.bn2.num_batches_tracked', 'model.base_model.model.ss_model.base.encoder_block5.conv_block1.conv1.base_layer.weight', 'model.base_model.model.ss_model.base.encoder_block5.conv_block1.conv1.lora_A.default.weight', 'model.base_model.model.ss_model.base.encoder_block5.conv_block1.conv1.lora_B.default.weight', 'model.base_model.model.ss_model.base.encoder_block5.conv_block1.conv2.base_layer.weight', 'model.base_model.model.ss_model.base.encoder_block5.conv_block1.conv2.lora_A.default.weight', 'model.base_model.model.ss_model.base.encoder_block5.conv_block1.conv2.lora_B.default.weight', 'model.base_model.model.ss_model.base.encoder_block5.conv_block1.shortcut.base_layer.weight', 'model.base_model.model.ss_model.base.encoder_block5.conv_block1.shortcut.base_layer.bias', 'model.base_model.model.ss_model.base.encoder_block5.conv_block1.shortcut.lora_A.default.weight', 'model.base_model.model.ss_model.base.encoder_block5.conv_block1.shortcut.lora_B.default.weight', 'model.base_model.model.ss_model.base.encoder_block6.conv_block1.bn1.weight', 'model.base_model.model.ss_model.base.encoder_block6.conv_block1.bn1.bias', 'model.base_model.model.ss_model.base.encoder_block6.conv_block1.bn1.running_mean', 'model.base_model.model.ss_model.base.encoder_block6.conv_block1.bn1.running_var', 'model.base_model.model.ss_model.base.encoder_block6.conv_block1.bn1.num_batches_tracked', 'model.base_model.model.ss_model.base.encoder_block6.conv_block1.bn2.weight', 'model.base_model.model.ss_model.base.encoder_block6.conv_block1.bn2.bias', 'model.base_model.model.ss_model.base.encoder_block6.conv_block1.bn2.running_mean', 'model.base_model.model.ss_model.base.encoder_block6.conv_block1.bn2.running_var', 'model.base_model.model.ss_model.base.encoder_block6.conv_block1.bn2.num_batches_tracked', 'model.base_model.model.ss_model.base.encoder_block6.conv_block1.conv1.base_layer.weight', 'model.base_model.model.ss_model.base.encoder_block6.conv_block1.conv1.lora_A.default.weight', 'model.base_model.model.ss_model.base.encoder_block6.conv_block1.conv1.lora_B.default.weight', 'model.base_model.model.ss_model.base.encoder_block6.conv_block1.conv2.base_layer.weight', 'model.base_model.model.ss_model.base.encoder_block6.conv_block1.conv2.lora_A.default.weight', 'model.base_model.model.ss_model.base.encoder_block6.conv_block1.conv2.lora_B.default.weight', 'model.base_model.model.ss_model.base.conv_block7a.conv_block1.bn1.weight', 'model.base_model.model.ss_model.base.conv_block7a.conv_block1.bn1.bias', 'model.base_model.model.ss_model.base.conv_block7a.conv_block1.bn1.running_mean', 'model.base_model.model.ss_model.base.conv_block7a.conv_block1.bn1.running_var', 'model.base_model.model.ss_model.base.conv_block7a.conv_block1.bn1.num_batches_tracked', 'model.base_model.model.ss_model.base.conv_block7a.conv_block1.bn2.weight', 'model.base_model.model.ss_model.base.conv_block7a.conv_block1.bn2.bias', 'model.base_model.model.ss_model.base.conv_block7a.conv_block1.bn2.running_mean', 'model.base_model.model.ss_model.base.conv_block7a.conv_block1.bn2.running_var', 'model.base_model.model.ss_model.base.conv_block7a.conv_block1.bn2.num_batches_tracked', 'model.base_model.model.ss_model.base.conv_block7a.conv_block1.conv1.base_layer.weight', 'model.base_model.model.ss_model.base.conv_block7a.conv_block1.conv1.lora_A.default.weight', 'model.base_model.model.ss_model.base.conv_block7a.conv_block1.conv1.lora_B.default.weight', 'model.base_model.model.ss_model.base.conv_block7a.conv_block1.conv2.base_layer.weight', 'model.base_model.model.ss_model.base.conv_block7a.conv_block1.conv2.lora_A.default.weight', 'model.base_model.model.ss_model.base.conv_block7a.conv_block1.conv2.lora_B.default.weight', 'model.base_model.model.ss_model.base.decoder_block1.conv1.weight', 'model.base_model.model.ss_model.base.decoder_block1.bn1.weight', 'model.base_model.model.ss_model.base.decoder_block1.bn1.bias', 'model.base_model.model.ss_model.base.decoder_block1.bn1.running_mean', 'model.base_model.model.ss_model.base.decoder_block1.bn1.running_var', 'model.base_model.model.ss_model.base.decoder_block1.bn1.num_batches_tracked', 'model.base_model.model.ss_model.base.decoder_block1.conv_block2.bn1.weight', 'model.base_model.model.ss_model.base.decoder_block1.conv_block2.bn1.bias', 'model.base_model.model.ss_model.base.decoder_block1.conv_block2.bn1.running_mean', 'model.base_model.model.ss_model.base.decoder_block1.conv_block2.bn1.running_var', 'model.base_model.model.ss_model.base.decoder_block1.conv_block2.bn1.num_batches_tracked', 'model.base_model.model.ss_model.base.decoder_block1.conv_block2.bn2.weight', 'model.base_model.model.ss_model.base.decoder_block1.conv_block2.bn2.bias', 'model.base_model.model.ss_model.base.decoder_block1.conv_block2.bn2.running_mean', 'model.base_model.model.ss_model.base.decoder_block1.conv_block2.bn2.running_var', 'model.base_model.model.ss_model.base.decoder_block1.conv_block2.bn2.num_batches_tracked', 'model.base_model.model.ss_model.base.decoder_block1.conv_block2.conv1.base_layer.weight', 'model.base_model.model.ss_model.base.decoder_block1.conv_block2.conv1.lora_A.default.weight', 'model.base_model.model.ss_model.base.decoder_block1.conv_block2.conv1.lora_B.default.weight', 'model.base_model.model.ss_model.base.decoder_block1.conv_block2.conv2.base_layer.weight', 'model.base_model.model.ss_model.base.decoder_block1.conv_block2.conv2.lora_A.default.weight', 'model.base_model.model.ss_model.base.decoder_block1.conv_block2.conv2.lora_B.default.weight', 'model.base_model.model.ss_model.base.decoder_block1.conv_block2.shortcut.base_layer.weight', 'model.base_model.model.ss_model.base.decoder_block1.conv_block2.shortcut.base_layer.bias', 'model.base_model.model.ss_model.base.decoder_block1.conv_block2.shortcut.lora_A.default.weight', 'model.base_model.model.ss_model.base.decoder_block1.conv_block2.shortcut.lora_B.default.weight', 'model.base_model.model.ss_model.base.decoder_block1.bn2.weight', 'model.base_model.model.ss_model.base.decoder_block1.bn2.bias', 'model.base_model.model.ss_model.base.decoder_block1.bn2.running_mean', 'model.base_model.model.ss_model.base.decoder_block1.bn2.running_var', 'model.base_model.model.ss_model.base.decoder_block1.bn2.num_batches_tracked', 'model.base_model.model.ss_model.base.decoder_block2.conv1.weight', 'model.base_model.model.ss_model.base.decoder_block2.bn1.weight', 'model.base_model.model.ss_model.base.decoder_block2.bn1.bias', 'model.base_model.model.ss_model.base.decoder_block2.bn1.running_mean', 'model.base_model.model.ss_model.base.decoder_block2.bn1.running_var', 'model.base_model.model.ss_model.base.decoder_block2.bn1.num_batches_tracked', 'model.base_model.model.ss_model.base.decoder_block2.conv_block2.bn1.weight', 'model.base_model.model.ss_model.base.decoder_block2.conv_block2.bn1.bias', 'model.base_model.model.ss_model.base.decoder_block2.conv_block2.bn1.running_mean', 'model.base_model.model.ss_model.base.decoder_block2.conv_block2.bn1.running_var', 'model.base_model.model.ss_model.base.decoder_block2.conv_block2.bn1.num_batches_tracked', 'model.base_model.model.ss_model.base.decoder_block2.conv_block2.bn2.weight', 'model.base_model.model.ss_model.base.decoder_block2.conv_block2.bn2.bias', 'model.base_model.model.ss_model.base.decoder_block2.conv_block2.bn2.running_mean', 'model.base_model.model.ss_model.base.decoder_block2.conv_block2.bn2.running_var', 'model.base_model.model.ss_model.base.decoder_block2.conv_block2.bn2.num_batches_tracked', 'model.base_model.model.ss_model.base.decoder_block2.conv_block2.conv1.base_layer.weight', 'model.base_model.model.ss_model.base.decoder_block2.conv_block2.conv1.lora_A.default.weight', 'model.base_model.model.ss_model.base.decoder_block2.conv_block2.conv1.lora_B.default.weight', 'model.base_model.model.ss_model.base.decoder_block2.conv_block2.conv2.base_layer.weight', 'model.base_model.model.ss_model.base.decoder_block2.conv_block2.conv2.lora_A.default.weight', 'model.base_model.model.ss_model.base.decoder_block2.conv_block2.conv2.lora_B.default.weight', 'model.base_model.model.ss_model.base.decoder_block2.conv_block2.shortcut.base_layer.weight', 'model.base_model.model.ss_model.base.decoder_block2.conv_block2.shortcut.base_layer.bias', 'model.base_model.model.ss_model.base.decoder_block2.conv_block2.shortcut.lora_A.default.weight', 'model.base_model.model.ss_model.base.decoder_block2.conv_block2.shortcut.lora_B.default.weight', 'model.base_model.model.ss_model.base.decoder_block2.bn2.weight', 'model.base_model.model.ss_model.base.decoder_block2.bn2.bias', 'model.base_model.model.ss_model.base.decoder_block2.bn2.running_mean', 'model.base_model.model.ss_model.base.decoder_block2.bn2.running_var', 'model.base_model.model.ss_model.base.decoder_block2.bn2.num_batches_tracked', 'model.base_model.model.ss_model.base.decoder_block3.conv1.weight', 'model.base_model.model.ss_model.base.decoder_block3.bn1.weight', 'model.base_model.model.ss_model.base.decoder_block3.bn1.bias', 'model.base_model.model.ss_model.base.decoder_block3.bn1.running_mean', 'model.base_model.model.ss_model.base.decoder_block3.bn1.running_var', 'model.base_model.model.ss_model.base.decoder_block3.bn1.num_batches_tracked', 'model.base_model.model.ss_model.base.decoder_block3.conv_block2.bn1.weight', 'model.base_model.model.ss_model.base.decoder_block3.conv_block2.bn1.bias', 'model.base_model.model.ss_model.base.decoder_block3.conv_block2.bn1.running_mean', 'model.base_model.model.ss_model.base.decoder_block3.conv_block2.bn1.running_var', 'model.base_model.model.ss_model.base.decoder_block3.conv_block2.bn1.num_batches_tracked', 'model.base_model.model.ss_model.base.decoder_block3.conv_block2.bn2.weight', 'model.base_model.model.ss_model.base.decoder_block3.conv_block2.bn2.bias', 'model.base_model.model.ss_model.base.decoder_block3.conv_block2.bn2.running_mean', 'model.base_model.model.ss_model.base.decoder_block3.conv_block2.bn2.running_var', 'model.base_model.model.ss_model.base.decoder_block3.conv_block2.bn2.num_batches_tracked', 'model.base_model.model.ss_model.base.decoder_block3.conv_block2.conv1.base_layer.weight', 'model.base_model.model.ss_model.base.decoder_block3.conv_block2.conv1.lora_A.default.weight', 'model.base_model.model.ss_model.base.decoder_block3.conv_block2.conv1.lora_B.default.weight', 'model.base_model.model.ss_model.base.decoder_block3.conv_block2.conv2.base_layer.weight', 'model.base_model.model.ss_model.base.decoder_block3.conv_block2.conv2.lora_A.default.weight', 'model.base_model.model.ss_model.base.decoder_block3.conv_block2.conv2.lora_B.default.weight', 'model.base_model.model.ss_model.base.decoder_block3.conv_block2.shortcut.base_layer.weight', 'model.base_model.model.ss_model.base.decoder_block3.conv_block2.shortcut.base_layer.bias', 'model.base_model.model.ss_model.base.decoder_block3.conv_block2.shortcut.lora_A.default.weight', 'model.base_model.model.ss_model.base.decoder_block3.conv_block2.shortcut.lora_B.default.weight', 'model.base_model.model.ss_model.base.decoder_block3.bn2.weight', 'model.base_model.model.ss_model.base.decoder_block3.bn2.bias', 'model.base_model.model.ss_model.base.decoder_block3.bn2.running_mean', 'model.base_model.model.ss_model.base.decoder_block3.bn2.running_var', 'model.base_model.model.ss_model.base.decoder_block3.bn2.num_batches_tracked', 'model.base_model.model.ss_model.base.decoder_block4.conv1.weight', 'model.base_model.model.ss_model.base.decoder_block4.bn1.weight', 'model.base_model.model.ss_model.base.decoder_block4.bn1.bias', 'model.base_model.model.ss_model.base.decoder_block4.bn1.running_mean', 'model.base_model.model.ss_model.base.decoder_block4.bn1.running_var', 'model.base_model.model.ss_model.base.decoder_block4.bn1.num_batches_tracked', 'model.base_model.model.ss_model.base.decoder_block4.conv_block2.bn1.weight', 'model.base_model.model.ss_model.base.decoder_block4.conv_block2.bn1.bias', 'model.base_model.model.ss_model.base.decoder_block4.conv_block2.bn1.running_mean', 'model.base_model.model.ss_model.base.decoder_block4.conv_block2.bn1.running_var', 'model.base_model.model.ss_model.base.decoder_block4.conv_block2.bn1.num_batches_tracked', 'model.base_model.model.ss_model.base.decoder_block4.conv_block2.bn2.weight', 'model.base_model.model.ss_model.base.decoder_block4.conv_block2.bn2.bias', 'model.base_model.model.ss_model.base.decoder_block4.conv_block2.bn2.running_mean', 'model.base_model.model.ss_model.base.decoder_block4.conv_block2.bn2.running_var', 'model.base_model.model.ss_model.base.decoder_block4.conv_block2.bn2.num_batches_tracked', 'model.base_model.model.ss_model.base.decoder_block4.conv_block2.conv1.base_layer.weight', 'model.base_model.model.ss_model.base.decoder_block4.conv_block2.conv1.lora_A.default.weight', 'model.base_model.model.ss_model.base.decoder_block4.conv_block2.conv1.lora_B.default.weight', 'model.base_model.model.ss_model.base.decoder_block4.conv_block2.conv2.base_layer.weight', 'model.base_model.model.ss_model.base.decoder_block4.conv_block2.conv2.lora_A.default.weight', 'model.base_model.model.ss_model.base.decoder_block4.conv_block2.conv2.lora_B.default.weight', 'model.base_model.model.ss_model.base.decoder_block4.conv_block2.shortcut.base_layer.weight', 'model.base_model.model.ss_model.base.decoder_block4.conv_block2.shortcut.base_layer.bias', 'model.base_model.model.ss_model.base.decoder_block4.conv_block2.shortcut.lora_A.default.weight', 'model.base_model.model.ss_model.base.decoder_block4.conv_block2.shortcut.lora_B.default.weight', 'model.base_model.model.ss_model.base.decoder_block4.bn2.weight', 'model.base_model.model.ss_model.base.decoder_block4.bn2.bias', 'model.base_model.model.ss_model.base.decoder_block4.bn2.running_mean', 'model.base_model.model.ss_model.base.decoder_block4.bn2.running_var', 'model.base_model.model.ss_model.base.decoder_block4.bn2.num_batches_tracked', 'model.base_model.model.ss_model.base.decoder_block5.conv1.weight', 'model.base_model.model.ss_model.base.decoder_block5.bn1.weight', 'model.base_model.model.ss_model.base.decoder_block5.bn1.bias', 'model.base_model.model.ss_model.base.decoder_block5.bn1.running_mean', 'model.base_model.model.ss_model.base.decoder_block5.bn1.running_var', 'model.base_model.model.ss_model.base.decoder_block5.bn1.num_batches_tracked', 'model.base_model.model.ss_model.base.decoder_block5.conv_block2.bn1.weight', 'model.base_model.model.ss_model.base.decoder_block5.conv_block2.bn1.bias', 'model.base_model.model.ss_model.base.decoder_block5.conv_block2.bn1.running_mean', 'model.base_model.model.ss_model.base.decoder_block5.conv_block2.bn1.running_var', 'model.base_model.model.ss_model.base.decoder_block5.conv_block2.bn1.num_batches_tracked', 'model.base_model.model.ss_model.base.decoder_block5.conv_block2.bn2.weight', 'model.base_model.model.ss_model.base.decoder_block5.conv_block2.bn2.bias', 'model.base_model.model.ss_model.base.decoder_block5.conv_block2.bn2.running_mean', 'model.base_model.model.ss_model.base.decoder_block5.conv_block2.bn2.running_var', 'model.base_model.model.ss_model.base.decoder_block5.conv_block2.bn2.num_batches_tracked', 'model.base_model.model.ss_model.base.decoder_block5.conv_block2.conv1.base_layer.weight', 'model.base_model.model.ss_model.base.decoder_block5.conv_block2.conv1.lora_A.default.weight', 'model.base_model.model.ss_model.base.decoder_block5.conv_block2.conv1.lora_B.default.weight', 'model.base_model.model.ss_model.base.decoder_block5.conv_block2.conv2.base_layer.weight', 'model.base_model.model.ss_model.base.decoder_block5.conv_block2.conv2.lora_A.default.weight', 'model.base_model.model.ss_model.base.decoder_block5.conv_block2.conv2.lora_B.default.weight', 'model.base_model.model.ss_model.base.decoder_block5.conv_block2.shortcut.base_layer.weight', 'model.base_model.model.ss_model.base.decoder_block5.conv_block2.shortcut.base_layer.bias', 'model.base_model.model.ss_model.base.decoder_block5.conv_block2.shortcut.lora_A.default.weight', 'model.base_model.model.ss_model.base.decoder_block5.conv_block2.shortcut.lora_B.default.weight', 'model.base_model.model.ss_model.base.decoder_block5.bn2.weight', 'model.base_model.model.ss_model.base.decoder_block5.bn2.bias', 'model.base_model.model.ss_model.base.decoder_block5.bn2.running_mean', 'model.base_model.model.ss_model.base.decoder_block5.bn2.running_var', 'model.base_model.model.ss_model.base.decoder_block5.bn2.num_batches_tracked', 'model.base_model.model.ss_model.base.decoder_block6.conv1.weight', 'model.base_model.model.ss_model.base.decoder_block6.bn1.weight', 'model.base_model.model.ss_model.base.decoder_block6.bn1.bias', 'model.base_model.model.ss_model.base.decoder_block6.bn1.running_mean', 'model.base_model.model.ss_model.base.decoder_block6.bn1.running_var', 'model.base_model.model.ss_model.base.decoder_block6.bn1.num_batches_tracked', 'model.base_model.model.ss_model.base.decoder_block6.conv_block2.bn1.weight', 'model.base_model.model.ss_model.base.decoder_block6.conv_block2.bn1.bias', 'model.base_model.model.ss_model.base.decoder_block6.conv_block2.bn1.running_mean', 'model.base_model.model.ss_model.base.decoder_block6.conv_block2.bn1.running_var', 'model.base_model.model.ss_model.base.decoder_block6.conv_block2.bn1.num_batches_tracked', 'model.base_model.model.ss_model.base.decoder_block6.conv_block2.bn2.weight', 'model.base_model.model.ss_model.base.decoder_block6.conv_block2.bn2.bias', 'model.base_model.model.ss_model.base.decoder_block6.conv_block2.bn2.running_mean', 'model.base_model.model.ss_model.base.decoder_block6.conv_block2.bn2.running_var', 'model.base_model.model.ss_model.base.decoder_block6.conv_block2.bn2.num_batches_tracked', 'model.base_model.model.ss_model.base.decoder_block6.conv_block2.conv1.base_layer.weight', 'model.base_model.model.ss_model.base.decoder_block6.conv_block2.conv1.lora_A.default.weight', 'model.base_model.model.ss_model.base.decoder_block6.conv_block2.conv1.lora_B.default.weight', 'model.base_model.model.ss_model.base.decoder_block6.conv_block2.conv2.base_layer.weight', 'model.base_model.model.ss_model.base.decoder_block6.conv_block2.conv2.lora_A.default.weight', 'model.base_model.model.ss_model.base.decoder_block6.conv_block2.conv2.lora_B.default.weight', 'model.base_model.model.ss_model.base.decoder_block6.conv_block2.shortcut.base_layer.weight', 'model.base_model.model.ss_model.base.decoder_block6.conv_block2.shortcut.base_layer.bias', 'model.base_model.model.ss_model.base.decoder_block6.conv_block2.shortcut.lora_A.default.weight', 'model.base_model.model.ss_model.base.decoder_block6.conv_block2.shortcut.lora_B.default.weight', 'model.base_model.model.ss_model.base.decoder_block6.bn2.weight', 'model.base_model.model.ss_model.base.decoder_block6.bn2.bias', 'model.base_model.model.ss_model.base.decoder_block6.bn2.running_mean', 'model.base_model.model.ss_model.base.decoder_block6.bn2.running_var', 'model.base_model.model.ss_model.base.decoder_block6.bn2.num_batches_tracked', 'model.base_model.model.ss_model.base.after_conv.base_layer.weight', 'model.base_model.model.ss_model.base.after_conv.base_layer.bias', 'model.base_model.model.ss_model.base.after_conv.lora_A.default.weight', 'model.base_model.model.ss_model.base.after_conv.lora_B.default.weight', 'model.base_model.model.ss_model.film.encoder_block1->conv_block1->beta1.weight', 'model.base_model.model.ss_model.film.encoder_block1->conv_block1->beta1.bias', 'model.base_model.model.ss_model.film.encoder_block1->conv_block1->beta2.weight', 'model.base_model.model.ss_model.film.encoder_block1->conv_block1->beta2.bias', 'model.base_model.model.ss_model.film.encoder_block2->conv_block1->beta1.weight', 'model.base_model.model.ss_model.film.encoder_block2->conv_block1->beta1.bias', 'model.base_model.model.ss_model.film.encoder_block2->conv_block1->beta2.weight', 'model.base_model.model.ss_model.film.encoder_block2->conv_block1->beta2.bias', 'model.base_model.model.ss_model.film.encoder_block3->conv_block1->beta1.weight', 'model.base_model.model.ss_model.film.encoder_block3->conv_block1->beta1.bias', 'model.base_model.model.ss_model.film.encoder_block3->conv_block1->beta2.weight', 'model.base_model.model.ss_model.film.encoder_block3->conv_block1->beta2.bias', 'model.base_model.model.ss_model.film.encoder_block4->conv_block1->beta1.weight', 'model.base_model.model.ss_model.film.encoder_block4->conv_block1->beta1.bias', 'model.base_model.model.ss_model.film.encoder_block4->conv_block1->beta2.weight', 'model.base_model.model.ss_model.film.encoder_block4->conv_block1->beta2.bias', 'model.base_model.model.ss_model.film.encoder_block5->conv_block1->beta1.weight', 'model.base_model.model.ss_model.film.encoder_block5->conv_block1->beta1.bias', 'model.base_model.model.ss_model.film.encoder_block5->conv_block1->beta2.weight', 'model.base_model.model.ss_model.film.encoder_block5->conv_block1->beta2.bias', 'model.base_model.model.ss_model.film.encoder_block6->conv_block1->beta1.weight', 'model.base_model.model.ss_model.film.encoder_block6->conv_block1->beta1.bias', 'model.base_model.model.ss_model.film.encoder_block6->conv_block1->beta2.weight', 'model.base_model.model.ss_model.film.encoder_block6->conv_block1->beta2.bias', 'model.base_model.model.ss_model.film.conv_block7a->conv_block1->beta1.weight', 'model.base_model.model.ss_model.film.conv_block7a->conv_block1->beta1.bias', 'model.base_model.model.ss_model.film.conv_block7a->conv_block1->beta2.weight', 'model.base_model.model.ss_model.film.conv_block7a->conv_block1->beta2.bias', 'model.base_model.model.ss_model.film.decoder_block1->beta1.weight', 'model.base_model.model.ss_model.film.decoder_block1->beta1.bias', 'model.base_model.model.ss_model.film.decoder_block1->beta2.weight', 'model.base_model.model.ss_model.film.decoder_block1->beta2.bias', 'model.base_model.model.ss_model.film.decoder_block1->conv_block2->beta1.weight', 'model.base_model.model.ss_model.film.decoder_block1->conv_block2->beta1.bias', 'model.base_model.model.ss_model.film.decoder_block1->conv_block2->beta2.weight', 'model.base_model.model.ss_model.film.decoder_block1->conv_block2->beta2.bias', 'model.base_model.model.ss_model.film.decoder_block2->beta1.weight', 'model.base_model.model.ss_model.film.decoder_block2->beta1.bias', 'model.base_model.model.ss_model.film.decoder_block2->beta2.weight', 'model.base_model.model.ss_model.film.decoder_block2->beta2.bias', 'model.base_model.model.ss_model.film.decoder_block2->conv_block2->beta1.weight', 'model.base_model.model.ss_model.film.decoder_block2->conv_block2->beta1.bias', 'model.base_model.model.ss_model.film.decoder_block2->conv_block2->beta2.weight', 'model.base_model.model.ss_model.film.decoder_block2->conv_block2->beta2.bias', 'model.base_model.model.ss_model.film.decoder_block3->beta1.weight', 'model.base_model.model.ss_model.film.decoder_block3->beta1.bias', 'model.base_model.model.ss_model.film.decoder_block3->beta2.weight', 'model.base_model.model.ss_model.film.decoder_block3->beta2.bias', 'model.base_model.model.ss_model.film.decoder_block3->conv_block2->beta1.weight', 'model.base_model.model.ss_model.film.decoder_block3->conv_block2->beta1.bias', 'model.base_model.model.ss_model.film.decoder_block3->conv_block2->beta2.weight', 'model.base_model.model.ss_model.film.decoder_block3->conv_block2->beta2.bias', 'model.base_model.model.ss_model.film.decoder_block4->beta1.weight', 'model.base_model.model.ss_model.film.decoder_block4->beta1.bias', 'model.base_model.model.ss_model.film.decoder_block4->beta2.weight', 'model.base_model.model.ss_model.film.decoder_block4->beta2.bias', 'model.base_model.model.ss_model.film.decoder_block4->conv_block2->beta1.weight', 'model.base_model.model.ss_model.film.decoder_block4->conv_block2->beta1.bias', 'model.base_model.model.ss_model.film.decoder_block4->conv_block2->beta2.weight', 'model.base_model.model.ss_model.film.decoder_block4->conv_block2->beta2.bias', 'model.base_model.model.ss_model.film.decoder_block5->beta1.weight', 'model.base_model.model.ss_model.film.decoder_block5->beta1.bias', 'model.base_model.model.ss_model.film.decoder_block5->beta2.weight', 'model.base_model.model.ss_model.film.decoder_block5->beta2.bias', 'model.base_model.model.ss_model.film.decoder_block5->conv_block2->beta1.weight', 'model.base_model.model.ss_model.film.decoder_block5->conv_block2->beta1.bias', 'model.base_model.model.ss_model.film.decoder_block5->conv_block2->beta2.weight', 'model.base_model.model.ss_model.film.decoder_block5->conv_block2->beta2.bias', 'model.base_model.model.ss_model.film.decoder_block6->beta1.weight', 'model.base_model.model.ss_model.film.decoder_block6->beta1.bias', 'model.base_model.model.ss_model.film.decoder_block6->beta2.weight', 'model.base_model.model.ss_model.film.decoder_block6->beta2.bias', 'model.base_model.model.ss_model.film.decoder_block6->conv_block2->beta1.weight', 'model.base_model.model.ss_model.film.decoder_block6->conv_block2->beta1.bias', 'model.base_model.model.ss_model.film.decoder_block6->conv_block2->beta2.weight', 'model.base_model.model.ss_model.film.decoder_block6->conv_block2->beta2.bias', 'model.base_model.model.query_encoder.model.logit_scale_a', 'model.base_model.model.query_encoder.model.logit_scale_t', 'model.base_model.model.query_encoder.model.audio_branch.spectrogram_extractor.stft.conv_real.weight', 'model.base_model.model.query_encoder.model.audio_branch.spectrogram_extractor.stft.conv_imag.weight', 'model.base_model.model.query_encoder.model.audio_branch.logmel_extractor.melW', 'model.base_model.model.query_encoder.model.audio_branch.bn0.weight', 'model.base_model.model.query_encoder.model.audio_branch.bn0.bias', 'model.base_model.model.query_encoder.model.audio_branch.bn0.running_mean', 'model.base_model.model.query_encoder.model.audio_branch.bn0.running_var', 'model.base_model.model.query_encoder.model.audio_branch.bn0.num_batches_tracked', 'model.base_model.model.query_encoder.model.audio_branch.patch_embed.proj.base_layer.weight', 'model.base_model.model.query_encoder.model.audio_branch.patch_embed.proj.base_layer.bias', 'model.base_model.model.query_encoder.model.audio_branch.patch_embed.proj.lora_A.default.weight', 'model.base_model.model.query_encoder.model.audio_branch.patch_embed.proj.lora_B.default.weight', 'model.base_model.model.query_encoder.model.audio_branch.patch_embed.norm.weight', 'model.base_model.model.query_encoder.model.audio_branch.patch_embed.norm.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.0.blocks.0.norm1.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.0.blocks.0.norm1.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.0.blocks.0.attn.relative_position_bias_table', 'model.base_model.model.query_encoder.model.audio_branch.layers.0.blocks.0.attn.relative_position_index', 'model.base_model.model.query_encoder.model.audio_branch.layers.0.blocks.0.attn.qkv.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.0.blocks.0.attn.qkv.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.0.blocks.0.attn.proj.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.0.blocks.0.attn.proj.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.0.blocks.0.norm2.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.0.blocks.0.norm2.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.0.blocks.0.mlp.fc1.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.0.blocks.0.mlp.fc1.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.0.blocks.0.mlp.fc2.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.0.blocks.0.mlp.fc2.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.0.blocks.1.attn_mask', 'model.base_model.model.query_encoder.model.audio_branch.layers.0.blocks.1.norm1.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.0.blocks.1.norm1.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.0.blocks.1.attn.relative_position_bias_table', 'model.base_model.model.query_encoder.model.audio_branch.layers.0.blocks.1.attn.relative_position_index', 'model.base_model.model.query_encoder.model.audio_branch.layers.0.blocks.1.attn.qkv.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.0.blocks.1.attn.qkv.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.0.blocks.1.attn.proj.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.0.blocks.1.attn.proj.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.0.blocks.1.norm2.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.0.blocks.1.norm2.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.0.blocks.1.mlp.fc1.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.0.blocks.1.mlp.fc1.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.0.blocks.1.mlp.fc2.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.0.blocks.1.mlp.fc2.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.0.downsample.reduction.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.0.downsample.norm.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.0.downsample.norm.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.1.blocks.0.norm1.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.1.blocks.0.norm1.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.1.blocks.0.attn.relative_position_bias_table', 'model.base_model.model.query_encoder.model.audio_branch.layers.1.blocks.0.attn.relative_position_index', 'model.base_model.model.query_encoder.model.audio_branch.layers.1.blocks.0.attn.qkv.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.1.blocks.0.attn.qkv.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.1.blocks.0.attn.proj.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.1.blocks.0.attn.proj.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.1.blocks.0.norm2.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.1.blocks.0.norm2.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.1.blocks.0.mlp.fc1.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.1.blocks.0.mlp.fc1.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.1.blocks.0.mlp.fc2.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.1.blocks.0.mlp.fc2.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.1.blocks.1.attn_mask', 'model.base_model.model.query_encoder.model.audio_branch.layers.1.blocks.1.norm1.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.1.blocks.1.norm1.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.1.blocks.1.attn.relative_position_bias_table', 'model.base_model.model.query_encoder.model.audio_branch.layers.1.blocks.1.attn.relative_position_index', 'model.base_model.model.query_encoder.model.audio_branch.layers.1.blocks.1.attn.qkv.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.1.blocks.1.attn.qkv.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.1.blocks.1.attn.proj.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.1.blocks.1.attn.proj.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.1.blocks.1.norm2.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.1.blocks.1.norm2.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.1.blocks.1.mlp.fc1.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.1.blocks.1.mlp.fc1.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.1.blocks.1.mlp.fc2.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.1.blocks.1.mlp.fc2.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.1.downsample.reduction.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.1.downsample.norm.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.1.downsample.norm.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.0.norm1.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.0.norm1.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.0.attn.relative_position_bias_table', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.0.attn.relative_position_index', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.0.attn.qkv.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.0.attn.qkv.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.0.attn.proj.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.0.attn.proj.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.0.norm2.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.0.norm2.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.0.mlp.fc1.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.0.mlp.fc1.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.0.mlp.fc2.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.0.mlp.fc2.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.1.attn_mask', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.1.norm1.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.1.norm1.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.1.attn.relative_position_bias_table', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.1.attn.relative_position_index', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.1.attn.qkv.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.1.attn.qkv.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.1.attn.proj.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.1.attn.proj.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.1.norm2.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.1.norm2.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.1.mlp.fc1.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.1.mlp.fc1.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.1.mlp.fc2.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.1.mlp.fc2.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.2.norm1.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.2.norm1.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.2.attn.relative_position_bias_table', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.2.attn.relative_position_index', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.2.attn.qkv.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.2.attn.qkv.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.2.attn.proj.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.2.attn.proj.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.2.norm2.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.2.norm2.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.2.mlp.fc1.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.2.mlp.fc1.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.2.mlp.fc2.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.2.mlp.fc2.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.3.attn_mask', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.3.norm1.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.3.norm1.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.3.attn.relative_position_bias_table', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.3.attn.relative_position_index', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.3.attn.qkv.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.3.attn.qkv.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.3.attn.proj.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.3.attn.proj.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.3.norm2.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.3.norm2.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.3.mlp.fc1.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.3.mlp.fc1.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.3.mlp.fc2.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.3.mlp.fc2.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.4.norm1.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.4.norm1.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.4.attn.relative_position_bias_table', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.4.attn.relative_position_index', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.4.attn.qkv.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.4.attn.qkv.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.4.attn.proj.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.4.attn.proj.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.4.norm2.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.4.norm2.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.4.mlp.fc1.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.4.mlp.fc1.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.4.mlp.fc2.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.4.mlp.fc2.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.5.attn_mask', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.5.norm1.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.5.norm1.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.5.attn.relative_position_bias_table', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.5.attn.relative_position_index', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.5.attn.qkv.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.5.attn.qkv.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.5.attn.proj.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.5.attn.proj.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.5.norm2.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.5.norm2.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.5.mlp.fc1.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.5.mlp.fc1.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.5.mlp.fc2.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.5.mlp.fc2.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.6.norm1.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.6.norm1.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.6.attn.relative_position_bias_table', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.6.attn.relative_position_index', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.6.attn.qkv.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.6.attn.qkv.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.6.attn.proj.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.6.attn.proj.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.6.norm2.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.6.norm2.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.6.mlp.fc1.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.6.mlp.fc1.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.6.mlp.fc2.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.6.mlp.fc2.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.7.attn_mask', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.7.norm1.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.7.norm1.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.7.attn.relative_position_bias_table', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.7.attn.relative_position_index', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.7.attn.qkv.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.7.attn.qkv.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.7.attn.proj.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.7.attn.proj.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.7.norm2.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.7.norm2.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.7.mlp.fc1.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.7.mlp.fc1.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.7.mlp.fc2.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.7.mlp.fc2.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.8.norm1.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.8.norm1.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.8.attn.relative_position_bias_table', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.8.attn.relative_position_index', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.8.attn.qkv.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.8.attn.qkv.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.8.attn.proj.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.8.attn.proj.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.8.norm2.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.8.norm2.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.8.mlp.fc1.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.8.mlp.fc1.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.8.mlp.fc2.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.8.mlp.fc2.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.9.attn_mask', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.9.norm1.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.9.norm1.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.9.attn.relative_position_bias_table', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.9.attn.relative_position_index', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.9.attn.qkv.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.9.attn.qkv.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.9.attn.proj.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.9.attn.proj.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.9.norm2.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.9.norm2.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.9.mlp.fc1.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.9.mlp.fc1.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.9.mlp.fc2.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.9.mlp.fc2.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.10.norm1.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.10.norm1.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.10.attn.relative_position_bias_table', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.10.attn.relative_position_index', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.10.attn.qkv.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.10.attn.qkv.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.10.attn.proj.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.10.attn.proj.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.10.norm2.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.10.norm2.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.10.mlp.fc1.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.10.mlp.fc1.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.10.mlp.fc2.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.10.mlp.fc2.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.11.attn_mask', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.11.norm1.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.11.norm1.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.11.attn.relative_position_bias_table', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.11.attn.relative_position_index', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.11.attn.qkv.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.11.attn.qkv.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.11.attn.proj.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.11.attn.proj.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.11.norm2.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.11.norm2.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.11.mlp.fc1.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.11.mlp.fc1.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.11.mlp.fc2.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.blocks.11.mlp.fc2.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.downsample.reduction.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.downsample.norm.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.2.downsample.norm.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.3.blocks.0.norm1.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.3.blocks.0.norm1.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.3.blocks.0.attn.relative_position_bias_table', 'model.base_model.model.query_encoder.model.audio_branch.layers.3.blocks.0.attn.relative_position_index', 'model.base_model.model.query_encoder.model.audio_branch.layers.3.blocks.0.attn.qkv.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.3.blocks.0.attn.qkv.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.3.blocks.0.attn.proj.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.3.blocks.0.attn.proj.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.3.blocks.0.norm2.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.3.blocks.0.norm2.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.3.blocks.0.mlp.fc1.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.3.blocks.0.mlp.fc1.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.3.blocks.0.mlp.fc2.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.3.blocks.0.mlp.fc2.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.3.blocks.1.norm1.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.3.blocks.1.norm1.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.3.blocks.1.attn.relative_position_bias_table', 'model.base_model.model.query_encoder.model.audio_branch.layers.3.blocks.1.attn.relative_position_index', 'model.base_model.model.query_encoder.model.audio_branch.layers.3.blocks.1.attn.qkv.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.3.blocks.1.attn.qkv.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.3.blocks.1.attn.proj.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.3.blocks.1.attn.proj.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.3.blocks.1.norm2.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.3.blocks.1.norm2.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.3.blocks.1.mlp.fc1.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.3.blocks.1.mlp.fc1.bias', 'model.base_model.model.query_encoder.model.audio_branch.layers.3.blocks.1.mlp.fc2.weight', 'model.base_model.model.query_encoder.model.audio_branch.layers.3.blocks.1.mlp.fc2.bias', 'model.base_model.model.query_encoder.model.audio_branch.norm.weight', 'model.base_model.model.query_encoder.model.audio_branch.norm.bias', 'model.base_model.model.query_encoder.model.audio_branch.tscam_conv.base_layer.weight', 'model.base_model.model.query_encoder.model.audio_branch.tscam_conv.base_layer.bias', 'model.base_model.model.query_encoder.model.audio_branch.tscam_conv.lora_A.default.weight', 'model.base_model.model.query_encoder.model.audio_branch.tscam_conv.lora_B.default.weight', 'model.base_model.model.query_encoder.model.audio_branch.head.weight', 'model.base_model.model.query_encoder.model.audio_branch.head.bias', 'model.base_model.model.query_encoder.model.text_branch.embeddings.position_ids', 'model.base_model.model.query_encoder.model.text_branch.embeddings.word_embeddings.weight', 'model.base_model.model.query_encoder.model.text_branch.embeddings.position_embeddings.weight', 'model.base_model.model.query_encoder.model.text_branch.embeddings.token_type_embeddings.weight', 'model.base_model.model.query_encoder.model.text_branch.embeddings.LayerNorm.weight', 'model.base_model.model.query_encoder.model.text_branch.embeddings.LayerNorm.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.0.attention.self.query.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.0.attention.self.query.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.0.attention.self.key.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.0.attention.self.key.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.0.attention.self.value.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.0.attention.self.value.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.0.attention.output.dense.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.0.attention.output.dense.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.0.attention.output.LayerNorm.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.0.attention.output.LayerNorm.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.0.intermediate.dense.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.0.intermediate.dense.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.0.output.dense.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.0.output.dense.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.0.output.LayerNorm.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.0.output.LayerNorm.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.1.attention.self.query.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.1.attention.self.query.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.1.attention.self.key.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.1.attention.self.key.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.1.attention.self.value.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.1.attention.self.value.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.1.attention.output.dense.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.1.attention.output.dense.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.1.attention.output.LayerNorm.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.1.attention.output.LayerNorm.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.1.intermediate.dense.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.1.intermediate.dense.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.1.output.dense.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.1.output.dense.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.1.output.LayerNorm.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.1.output.LayerNorm.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.2.attention.self.query.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.2.attention.self.query.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.2.attention.self.key.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.2.attention.self.key.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.2.attention.self.value.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.2.attention.self.value.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.2.attention.output.dense.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.2.attention.output.dense.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.2.attention.output.LayerNorm.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.2.attention.output.LayerNorm.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.2.intermediate.dense.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.2.intermediate.dense.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.2.output.dense.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.2.output.dense.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.2.output.LayerNorm.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.2.output.LayerNorm.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.3.attention.self.query.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.3.attention.self.query.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.3.attention.self.key.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.3.attention.self.key.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.3.attention.self.value.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.3.attention.self.value.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.3.attention.output.dense.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.3.attention.output.dense.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.3.attention.output.LayerNorm.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.3.attention.output.LayerNorm.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.3.intermediate.dense.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.3.intermediate.dense.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.3.output.dense.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.3.output.dense.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.3.output.LayerNorm.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.3.output.LayerNorm.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.4.attention.self.query.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.4.attention.self.query.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.4.attention.self.key.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.4.attention.self.key.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.4.attention.self.value.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.4.attention.self.value.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.4.attention.output.dense.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.4.attention.output.dense.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.4.attention.output.LayerNorm.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.4.attention.output.LayerNorm.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.4.intermediate.dense.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.4.intermediate.dense.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.4.output.dense.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.4.output.dense.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.4.output.LayerNorm.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.4.output.LayerNorm.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.5.attention.self.query.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.5.attention.self.query.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.5.attention.self.key.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.5.attention.self.key.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.5.attention.self.value.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.5.attention.self.value.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.5.attention.output.dense.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.5.attention.output.dense.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.5.attention.output.LayerNorm.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.5.attention.output.LayerNorm.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.5.intermediate.dense.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.5.intermediate.dense.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.5.output.dense.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.5.output.dense.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.5.output.LayerNorm.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.5.output.LayerNorm.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.6.attention.self.query.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.6.attention.self.query.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.6.attention.self.key.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.6.attention.self.key.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.6.attention.self.value.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.6.attention.self.value.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.6.attention.output.dense.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.6.attention.output.dense.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.6.attention.output.LayerNorm.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.6.attention.output.LayerNorm.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.6.intermediate.dense.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.6.intermediate.dense.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.6.output.dense.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.6.output.dense.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.6.output.LayerNorm.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.6.output.LayerNorm.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.7.attention.self.query.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.7.attention.self.query.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.7.attention.self.key.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.7.attention.self.key.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.7.attention.self.value.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.7.attention.self.value.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.7.attention.output.dense.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.7.attention.output.dense.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.7.attention.output.LayerNorm.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.7.attention.output.LayerNorm.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.7.intermediate.dense.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.7.intermediate.dense.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.7.output.dense.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.7.output.dense.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.7.output.LayerNorm.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.7.output.LayerNorm.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.8.attention.self.query.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.8.attention.self.query.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.8.attention.self.key.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.8.attention.self.key.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.8.attention.self.value.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.8.attention.self.value.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.8.attention.output.dense.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.8.attention.output.dense.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.8.attention.output.LayerNorm.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.8.attention.output.LayerNorm.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.8.intermediate.dense.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.8.intermediate.dense.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.8.output.dense.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.8.output.dense.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.8.output.LayerNorm.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.8.output.LayerNorm.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.9.attention.self.query.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.9.attention.self.query.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.9.attention.self.key.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.9.attention.self.key.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.9.attention.self.value.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.9.attention.self.value.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.9.attention.output.dense.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.9.attention.output.dense.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.9.attention.output.LayerNorm.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.9.attention.output.LayerNorm.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.9.intermediate.dense.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.9.intermediate.dense.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.9.output.dense.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.9.output.dense.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.9.output.LayerNorm.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.9.output.LayerNorm.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.10.attention.self.query.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.10.attention.self.query.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.10.attention.self.key.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.10.attention.self.key.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.10.attention.self.value.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.10.attention.self.value.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.10.attention.output.dense.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.10.attention.output.dense.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.10.attention.output.LayerNorm.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.10.attention.output.LayerNorm.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.10.intermediate.dense.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.10.intermediate.dense.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.10.output.dense.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.10.output.dense.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.10.output.LayerNorm.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.10.output.LayerNorm.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.11.attention.self.query.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.11.attention.self.query.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.11.attention.self.key.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.11.attention.self.key.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.11.attention.self.value.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.11.attention.self.value.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.11.attention.output.dense.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.11.attention.output.dense.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.11.attention.output.LayerNorm.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.11.attention.output.LayerNorm.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.11.intermediate.dense.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.11.intermediate.dense.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.11.output.dense.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.11.output.dense.bias', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.11.output.LayerNorm.weight', 'model.base_model.model.query_encoder.model.text_branch.encoder.layer.11.output.LayerNorm.bias', 'model.base_model.model.query_encoder.model.text_branch.pooler.dense.weight', 'model.base_model.model.query_encoder.model.text_branch.pooler.dense.bias', 'model.base_model.model.query_encoder.model.text_transform.sequential.0.weight', 'model.base_model.model.query_encoder.model.text_transform.sequential.0.bias', 'model.base_model.model.query_encoder.model.text_transform.sequential.3.weight', 'model.base_model.model.query_encoder.model.text_transform.sequential.3.bias', 'model.base_model.model.query_encoder.model.text_projection.0.weight', 'model.base_model.model.query_encoder.model.text_projection.0.bias', 'model.base_model.model.query_encoder.model.text_projection.2.weight', 'model.base_model.model.query_encoder.model.text_projection.2.bias', 'model.base_model.model.query_encoder.model.audio_transform.sequential.0.weight', 'model.base_model.model.query_encoder.model.audio_transform.sequential.0.bias', 'model.base_model.model.query_encoder.model.audio_transform.sequential.3.weight', 'model.base_model.model.query_encoder.model.audio_transform.sequential.3.bias', 'model.base_model.model.query_encoder.model.audio_projection.0.weight', 'model.base_model.model.query_encoder.model.audio_projection.0.bias', 'model.base_model.model.query_encoder.model.audio_projection.2.weight', 'model.base_model.model.query_encoder.model.audio_projection.2.bias'])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint['state_dict'].keys()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-23T17:12:26.522728258Z",
     "start_time": "2024-02-23T17:12:26.510155500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "38"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint['epoch']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T15:11:27.025676281Z",
     "start_time": "2024-02-24T15:11:27.013523797Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
