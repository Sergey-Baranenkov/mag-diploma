{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Визуализация работы FAISS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T17:33:01.816860361Z",
     "start_time": "2024-04-09T17:33:01.816600776Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Получаем абсолютный путь к корневой директории проекта (директория выше текущей)\n",
    "root_path = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "# Добавляем корневую директорию в sys.path\n",
    "if root_path not in sys.path:\n",
    "    sys.path.append(root_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T17:33:01.818106717Z",
     "start_time": "2024-04-09T17:33:01.817055052Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils import parse_yaml\n",
    "from models.clap_encoder import CLAP_Encoder\n",
    "import faiss\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T18:10:28.370955688Z",
     "start_time": "2024-04-09T18:10:28.338373182Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "SS_CONFIG_PATH = '../config/audiosep_base.yaml'\n",
    "CLAP_CKPT_PATH = '../checkpoint/music_speech_audioset_epoch_15_esc_89.98.pt'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T17:33:06.510489447Z",
     "start_time": "2024-04-09T17:33:06.479622743Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/araxal/anaconda3/envs/AudioSep/lib/python3.10/site-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3549.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "configs = parse_yaml(SS_CONFIG_PATH)\n",
    "\n",
    "query_encoder = CLAP_Encoder(pretrained_path = CLAP_CKPT_PATH).eval().to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T17:33:09.616054861Z",
     "start_time": "2024-04-09T17:33:06.510986955Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "# Эмбеддинги, которые сохраняем в бд\n",
    "saved_classes = ['vocal', 'drums', 'guitar', 'hippopotamus', 'roar', 'blender']\n",
    "# Запросы, к которым будем искать ближайший класс из бд\n",
    "query_classes = ['kick', 'ukulele', 'singing', 'howl', 'scream']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T18:00:53.516231950Z",
     "start_time": "2024-04-09T18:00:53.439399472Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([6, 512]), torch.Size([5, 512]))"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_to_save = query_encoder.get_query_embed(modality='text', text=saved_classes).cpu()\n",
    "embeddings_to_query = query_encoder.get_query_embed(modality='text', text=query_classes).cpu()\n",
    "embeddings_to_save.shape, embeddings_to_query.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T18:00:53.687342534Z",
     "start_time": "2024-04-09T18:00:53.599650373Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "index = faiss.IndexHNSWFlat(512, 32)\n",
    "index.add(embeddings_to_save)\n",
    "distances, indices = index.search(embeddings_to_query, k = len(saved_classes))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T18:00:53.749856577Z",
     "start_time": "2024-04-09T18:00:53.749654732Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.0701145 , 1.3757946 , 1.4211205 , 1.4345753 , 1.5783528 ,\n        1.6412584 ],\n       [1.1907144 , 1.3707284 , 1.3740044 , 1.4348282 , 1.8569329 ,\n        1.8919489 ],\n       [0.5037271 , 0.9429968 , 0.98835295, 1.4366088 , 1.5765313 ,\n        1.9686406 ],\n       [0.9751475 , 0.9951929 , 1.2816312 , 1.4155016 , 1.5595326 ,\n        1.8042557 ],\n       [1.0844126 , 1.0952895 , 1.2217162 , 1.3817437 , 1.5443419 ,\n        1.5597425 ]], dtype=float32)"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T18:00:53.901248771Z",
     "start_time": "2024-04-09T18:00:53.866963752Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1, 0, 2, 4, 3, 5],\n       [2, 0, 3, 1, 5, 4],\n       [0, 1, 3, 2, 5, 4],\n       [3, 0, 1, 2, 4, 5],\n       [1, 3, 0, 2, 5, 4]])"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T18:00:54.067816785Z",
     "start_time": "2024-04-09T18:00:54.066335541Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class kick, nearest classes: ['drums__1.07', 'vocal__1.38', 'guitar__1.42', 'roar__1.43', 'hippopotamus__1.58', 'blender__1.64'], difference between top 1 and top2: 0.30568015575408936 difference between top 1 and last: 0.5711438655853271\n",
      "Class ukulele, nearest classes: ['guitar__1.19', 'vocal__1.37', 'hippopotamus__1.37', 'drums__1.43', 'blender__1.86', 'roar__1.89'], difference between top 1 and top2: 0.1800140142440796 difference between top 1 and last: 0.7012345790863037\n",
      "Class singing, nearest classes: ['vocal__0.50', 'drums__0.94', 'hippopotamus__0.99', 'guitar__1.44', 'blender__1.58', 'roar__1.97'], difference between top 1 and top2: 0.4392697215080261 difference between top 1 and last: 1.4649134874343872\n",
      "Class howl, nearest classes: ['hippopotamus__0.98', 'vocal__1.00', 'drums__1.28', 'guitar__1.42', 'roar__1.56', 'blender__1.80'], difference between top 1 and top2: 0.02004539966583252 difference between top 1 and last: 0.8291082382202148\n",
      "Class scream, nearest classes: ['drums__1.08', 'hippopotamus__1.10', 'vocal__1.22', 'guitar__1.38', 'blender__1.54', 'roar__1.56'], difference between top 1 and top2: 0.010876893997192383 difference between top 1 and last: 0.4753298759460449\n"
     ]
    }
   ],
   "source": [
    "for i, query_class in enumerate(query_classes):\n",
    "    k_nearest_indices = indices[i]\n",
    "    k_nearest_distances = distances[i]\n",
    "    class_distance_tuples = [\n",
    "        (saved_classes[class_index], distance) for class_index, distance in zip(k_nearest_indices, k_nearest_distances)]\n",
    "\n",
    "    k_nearest_names = [f'{cls}__{dist:.2f}' for (cls, dist) in class_distance_tuples]\n",
    "    difference_between_top2 = class_distance_tuples[1][1] - class_distance_tuples[0][1]\n",
    "    difference_between_last = class_distance_tuples[len(k_nearest_distances) - 1][1] - class_distance_tuples[0][1]\n",
    "\n",
    "    print(f'Class {query_class}, '\n",
    "          f'nearest classes: {k_nearest_names}, '\n",
    "          f'difference between top 1 and top2: {difference_between_top2} '\n",
    "          f'difference between top 1 and last: {difference_between_last}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T18:28:55.188882972Z",
     "start_time": "2024-04-09T18:28:55.148197579Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(1.0000)"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.square(embeddings_to_save[0]).sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T18:14:04.197201275Z",
     "start_time": "2024-04-09T18:14:04.150059079Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Вектора нормализованы, по неравенству треугольника максимальное расстояние между векторами = 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Видно, что энкодер правильно нашел ближайший класс для классов kick, ukulele и singing.\n",
    "\n",
    "Однако для классов howl и scream энкодер не нашел класс roar, являющийся очевидным синонимом. Возможно такого класса не было в словаре у энкодера.\n",
    "\n",
    "Также отметим, что для каждого класса из запроса имелся только один правильный класс, сохраненный в базе данных, однако разница между топ 1 и топ 2 классами для неправильно определенных классов и для класса vocal оказалась незначительной, что может говорить о несовершенстве энкодера.\n",
    "\n",
    "Также для самого близкого класса singing ближайший класс vocal лежит на расстоянии 0.5 (L2 norm). Это намного ближе относительно второго места, однако если посмотреть на первые места сложно определить правильный threshold (когда использовать адаптер, а когда базовую модель) для синонимичных классов.\n",
    "\n",
    "Однако исходя из того, что CLAP является SOTA решением для определения близости captions в контексте звука, решено использовать в качестве эмбеддера именно его."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
